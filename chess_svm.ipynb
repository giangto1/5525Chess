{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d263b1-844d-4df0-98bd-d314a7461249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc1758b-ab3a-431e-85bd-ec4820a68050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/giangto/Documents/umn/csci5525/5525Chess\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "current = os.getcwd()\n",
    "data_folder = os.path.join(current, \"normalized_images_64\")\n",
    "chess_types_folders = glob.glob(os.path.join(data_folder, \"*\"))\n",
    "# print(chess_types_folders)\n",
    "pieces_info = []\n",
    "labels = {\"King\": 1, \"Knight\":2, \"Bishop\":3, \"Rook\":4, \"Pawn\":5, \"Queen\":6}\n",
    "for chess_types in chess_types_folders:\n",
    "    pieces = glob.glob(f'{chess_types}/*')\n",
    "    # print(pieces)\n",
    "    type = chess_types.split(\"/\")[-1]\n",
    "    for piece in pieces:\n",
    "        p = {\"normalized_img\": np.load(piece).reshape(-1), \"label\": labels[type]}\n",
    "        pieces_info.append(p)\n",
    "chess_df = pd.DataFrame(pieces_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "518ce24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        normalized_img  label\n",
      "783  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...      6\n",
      "820  [0.403921568627451, 0.38823529411764707, 0.372...      6\n",
      "745  [0.24705882352941178, 0.3137254901960784, 0.77...      6\n",
      "848  [0.5450980392156862, 0.5803921568627451, 0.607...      6\n",
      "836  [0.5882352941176471, 0.792156862745098, 0.8196...      6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/pqhy6s2j2lq2h7_jn7jz7gpr0000gn/T/ipykernel_823/449878163.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  chess_df = chess_df.applymap(lambda x: tuple(x) if isinstance(x, np.ndarray) else x)\n",
      "/var/folders/tp/pqhy6s2j2lq2h7_jn7jz7gpr0000gn/T/ipykernel_823/449878163.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  chess_test = chess_test.applymap(lambda x: tuple(x) if isinstance(x, np.ndarray) else x)\n"
     ]
    }
   ],
   "source": [
    "#sample df test set and df train set\n",
    "chess_test = pd.DataFrame()\n",
    "for i in range(1,7):\n",
    "    chess_i = chess_df[chess_df[\"label\"]==i].sample(frac=0.3)\n",
    "    chess_test = pd.concat([chess_i,chess_test])\n",
    "chess_test = chess_test[chess_df.columns]\n",
    "print(chess_test.head())\n",
    "chess_df = chess_df.applymap(lambda x: tuple(x) if isinstance(x, np.ndarray) else x)\n",
    "chess_test = chess_test.applymap(lambda x: tuple(x) if isinstance(x, np.ndarray) else x)\n",
    "\n",
    "# Merge\n",
    "chess_train = chess_df.merge(chess_test, how='left', indicator=True)\n",
    "chess_train = chess_train[chess_train['_merge'] == 'left_only'].drop(columns='_merge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b18cee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chess train labels:  label\n",
      "5    109\n",
      "2    109\n",
      "4    106\n",
      "3     95\n",
      "6     90\n",
      "1     88\n",
      "Name: count, dtype: int64\n",
      "chess test labels:  label\n",
      "5    47\n",
      "2    47\n",
      "4    46\n",
      "3    41\n",
      "6    38\n",
      "1    38\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"chess train labels: \", chess_train[\"label\"].value_counts())\n",
    "print(\"chess test labels: \", chess_test[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa8c986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.509728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.663282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label\n",
       "count  257.000000\n",
       "mean     3.509728\n",
       "std      1.663282\n",
       "min      1.000000\n",
       "25%      2.000000\n",
       "50%      4.000000\n",
       "75%      5.000000\n",
       "max      6.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa9177a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      normalized_img  label\n",
      "0  (0.2196078431372549, 0.2235294117647059, 0.227...      3\n",
      "1  (1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...      3\n",
      "2  (0.8666666666666667, 0.8666666666666667, 0.866...      3\n",
      "3  (1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...      3\n",
      "4  (0.6862745098039216, 0.6823529411764706, 0.690...      3\n"
     ]
    }
   ],
   "source": [
    "print(chess_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c292719e-7e69-41ba-8a3e-f1dcc6fbd39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_df.iloc[0:5]['normalized_img'].shape #dim of 1 single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04cc4226-bb47-4d16-8bff-fdcebad37664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21960784, 0.22352941, 0.22745098, ..., 0.76078431, 0.76078431,\n",
       "       0.76078431], shape=(50176,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_df.iloc[0]['normalized_img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f945153b-37fb-4477-ae87-09af1eeec8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "X_train = np.array(chess_train['normalized_img'])\n",
    "X_train = np.array([x for x in X_train])\n",
    "y_train = np.array(chess_train['label'])\n",
    "\n",
    "X_test = np.array(chess_test['normalized_img'])\n",
    "X_test = np.array([x for x in X_test])\n",
    "y_test = np.array(chess_test['label'])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eebf91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbc0472e-651b-49c3-8eba-d58f828fb7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01: (avg train error, avg validation error) = (0.0000, 0.0000)\n",
      "C = 0.1: (avg train error, avg validation error) = (0.0000, 0.0000)\n",
      "C = 1.0: (avg train error, avg validation error) = (0.0000, 0.0000)\n",
      "C = 10: (avg train error, avg validation error) = (0.0000, 0.0000)\n",
      "C = 100: (avg train error, avg validation error) = (0.0000, 0.0000)\n"
     ]
    }
   ],
   "source": [
    "#Selecting best C for Linear SVM Model\n",
    "C_values = [0.01, 0.1, 1.0, 10, 100]\n",
    "cv_val_avg_score = []\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for C in C_values:\n",
    "\ttrain_errors = []\n",
    "\tval_errors = []\n",
    "\tfor train_idx, val_idx in skf.split(X_train, y_train):\n",
    "\t\tX_train_cv, X_val = X_train[train_idx], X_train[val_idx]\n",
    "\t\ty_train_cv, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\t\tlin_svm = SVC(kernel='linear',C=C)\n",
    "\t\tlin_svm.fit(X_train, y_train)\n",
    "\t\t# validation error\n",
    "\t\ty_val_pred = lin_svm.predict(X_val)\n",
    "\t\tval_error = 1 - accuracy_score(y_val, y_val_pred)\n",
    "\t\tval_errors.append(val_error)\n",
    "\n",
    "\t\t# train error\n",
    "\t\ty_train_pred = lin_svm.predict(X_train_cv)\n",
    "\t\ttrain_error = 1 - accuracy_score(y_train_cv, y_train_pred)\n",
    "\t\ttrain_errors.append(train_error)\n",
    "\n",
    "\tavg_val_error = np.mean(val_errors)\n",
    "\tavg_train_error = np.mean(train_errors)\n",
    "\n",
    "\t# Report validation, test for each C\n",
    "\tprint(f\"C = {C}: (avg train error, avg validation error) = ({avg_train_error:.4f}, {avg_val_error:.4f})\")\n",
    "\n",
    "\tcv_val_avg_score.append(avg_val_error)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "595bdf49-7f0f-4523-adf1-450fcc8b9bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C = 0.01, with lowest avg test error: 0.0000\n",
      "Final Test Error: 0.8132\n",
      "Linear SVM Performance Metrics with C=0.01:\n",
      "Accuracy: 0.1868\n",
      "Precision: 0.1845\n",
      "Recall: 0.1868\n",
      "F1 Score: 0.1846\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 6  6  4  6 10  6]\n",
      " [ 6 15  5  5 13  3]\n",
      " [ 7  8  5  5  6 10]\n",
      " [ 5  9  6 10  9  7]\n",
      " [ 4 10  9  9  5 10]\n",
      " [ 5  9  4  7  6  7]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.18      0.16      0.17        38\n",
      "           2       0.26      0.32      0.29        47\n",
      "           3       0.15      0.12      0.14        41\n",
      "           4       0.24      0.22      0.23        46\n",
      "           5       0.10      0.11      0.10        47\n",
      "           6       0.16      0.18      0.17        38\n",
      "\n",
      "    accuracy                           0.19       257\n",
      "   macro avg       0.18      0.18      0.18       257\n",
      "weighted avg       0.18      0.19      0.18       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fit linear model on best C\n",
    "lowest_val_error_index = np.argmin(cv_val_avg_score)\n",
    "C_chosen = C_values[lowest_val_error_index]\n",
    "\n",
    "print(f\"Best C = {C_chosen}, with lowest avg test error: {cv_val_avg_score[lowest_val_error_index]:.4f}\")\n",
    "\n",
    "\n",
    "final_model = SVC(kernel='linear',C=C_chosen)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "final_test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred, average='weighted')  # Use 'macro' or 'weighted' for multi-class\n",
    "recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final Test Error: {final_test_error:.4f}\")\n",
    "print(f\"Linear SVM Performance Metrics with C={C_chosen}:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfd9167d-5723-46c7-a81b-92988a237983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01: (avg train error, avg validation error) = (0.7722, 0.7722)\n",
      "C = 0.1: (avg train error, avg validation error) = (0.7722, 0.7722)\n",
      "C = 1.0: (avg train error, avg validation error) = (0.2730, 0.2730)\n",
      "C = 10: (avg train error, avg validation error) = (0.0335, 0.0335)\n",
      "C = 100: (avg train error, avg validation error) = (0.0000, 0.0000)\n"
     ]
    }
   ],
   "source": [
    "#Selecting best C for RBF SVM Model (gamma=auto)\n",
    "C_values = [0.01, 0.1, 1.0, 10,100]\n",
    "cv_val_avg_score = []\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for C in C_values:\n",
    "\ttrain_errors = []\n",
    "\tval_errors = []\n",
    "\tfor train_idx, val_idx in skf.split(X_train, y_train):\n",
    "\t\tX_train_cv, X_val = X_train[train_idx], X_train[val_idx]\n",
    "\t\ty_train_cv, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\t\tauto_svm = SVC(kernel='rbf',C=C, gamma='auto')\n",
    "\t\tauto_svm.fit(X_train, y_train)\n",
    "\t\t# validation error\n",
    "\t\ty_val_pred = auto_svm.predict(X_val)\n",
    "\t\tval_error = 1 - accuracy_score(y_val, y_val_pred)\n",
    "\t\tval_errors.append(val_error)\n",
    "\n",
    "\t\t# train error\n",
    "\t\ty_train_pred = auto_svm.predict(X_train_cv)\n",
    "\t\ttrain_error = 1 - accuracy_score(y_train_cv, y_train_pred)\n",
    "\t\ttrain_errors.append(train_error)\n",
    "\n",
    "\tavg_val_error = np.mean(val_errors)\n",
    "\tavg_train_error = np.mean(train_errors)\n",
    "\n",
    "\t# Report validation, test for each C\n",
    "\tprint(f\"C = {C}: (avg train error, avg validation error) = ({avg_train_error:.4f}, {avg_val_error:.4f})\")\n",
    "\n",
    "\tcv_val_avg_score.append(avg_val_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1db16077-645f-4633-9677-8c983799bbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C = 100, with lowest avg test error: 0.0000\n",
      "Final Test Error: 0.7393\n",
      "RBF SVM Performance Metrics with C=100, gamma='auto':\n",
      "Accuracy: 0.2607\n",
      "Precision: 0.2690\n",
      "Recall: 0.2607\n",
      "F1 Score: 0.2617\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 6  5  6  4 10  7]\n",
      " [ 2 20 12  2  7  4]\n",
      " [ 7  5  7  4  4 14]\n",
      " [ 3 10  4 13 10  6]\n",
      " [ 4  8  6  7 12 10]\n",
      " [ 5  1  5  4 14  9]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.22      0.16      0.18        38\n",
      "           2       0.41      0.43      0.42        47\n",
      "           3       0.17      0.17      0.17        41\n",
      "           4       0.38      0.28      0.33        46\n",
      "           5       0.21      0.26      0.23        47\n",
      "           6       0.18      0.24      0.20        38\n",
      "\n",
      "    accuracy                           0.26       257\n",
      "   macro avg       0.26      0.25      0.26       257\n",
      "weighted avg       0.27      0.26      0.26       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fit RBF model on best C (gamma='auto')\n",
    "lowest_val_error_index = np.argmin(cv_val_avg_score)\n",
    "C_chosen = C_values[lowest_val_error_index]\n",
    "\n",
    "print(f\"Best C = {C_chosen}, with lowest avg test error: {cv_val_avg_score[lowest_val_error_index]:.4f}\")\n",
    "\n",
    "\n",
    "final_model = SVC(kernel='rbf',C=14, gamma='auto')\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "final_test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred, average='weighted')  # Use 'macro' or 'weighted' for multi-class\n",
    "recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final Test Error: {final_test_error:.4f}\")\n",
    "print(f\"RBF SVM Performance Metrics with C={C_chosen}, gamma='auto':\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7d2fd07-3c95-42b3-93aa-34ae4462bad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01: (avg train error, avg validation error) = (0.7722, 0.7722)\n",
      "C = 0.1: (avg train error, avg validation error) = (0.7722, 0.7722)\n",
      "C = 1.0: (avg train error, avg validation error) = (0.2730, 0.2730)\n",
      "C = 10: (avg train error, avg validation error) = (0.0335, 0.0335)\n",
      "C = 100: (avg train error, avg validation error) = (0.0000, 0.0000)\n"
     ]
    }
   ],
   "source": [
    "#Selecting best C for RBF SVM Model (gamma=scale)\n",
    "C_values = [0.01, 0.1, 1.0, 10, 100]\n",
    "cv_val_avg_score = []\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for C in C_values:\n",
    "\ttrain_errors = []\n",
    "\tval_errors = []\n",
    "\tfor train_idx, val_idx in skf.split(X_train, y_train):\n",
    "\t\tX_train_cv, X_val = X_train[train_idx], X_train[val_idx]\n",
    "\t\ty_train_cv, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\t\tscale_svm = SVC(kernel='rbf',C=C, gamma='scale')\n",
    "\t\tscale_svm.fit(X_train, y_train)\n",
    "\t\t# validation error\n",
    "\t\ty_val_pred = scale_svm.predict(X_val)\n",
    "\t\tval_error = 1 - accuracy_score(y_val, y_val_pred)\n",
    "\t\tval_errors.append(val_error)\n",
    "\n",
    "\t\t# train error\n",
    "\t\ty_train_pred = scale_svm.predict(X_train_cv)\n",
    "\t\ttrain_error = 1 - accuracy_score(y_train_cv, y_train_pred)\n",
    "\t\ttrain_errors.append(train_error)\n",
    "\n",
    "\tavg_val_error = np.mean(val_errors)\n",
    "\tavg_train_error = np.mean(train_errors)\n",
    "\n",
    "\t# Report validation, test for each C\n",
    "\tprint(f\"C = {C}: (avg train error, avg validation error) = ({avg_train_error:.4f}, {avg_val_error:.4f})\")\n",
    "\n",
    "\tcv_val_avg_score.append(avg_val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9c0021f-c910-47d2-8bfd-b5335f06d148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C = 100, with lowest avg test error: 0.0000\n",
      "Final Test Error: 0.7169\n",
      "RBF SVM Performance Metrics with C=100, gamma='scale':\n",
      "Accuracy: 0.2831\n",
      "Precision: 0.3561\n",
      "Recall: 0.2831\n",
      "F1 Score: 0.3122\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  6  7  2  6 10]\n",
      " [ 2 19  7  7  4  8]\n",
      " [ 5  5  8  5  7 11]\n",
      " [ 2 11  7 13  6  7]\n",
      " [ 4  7  4  7 15 10]\n",
      " [ 0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.18      0.24        38\n",
      "           2       0.40      0.40      0.40        47\n",
      "           3       0.24      0.20      0.22        41\n",
      "           4       0.38      0.28      0.33        46\n",
      "           5       0.39      0.32      0.35        47\n",
      "           6       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.28       219\n",
      "   macro avg       0.29      0.23      0.26       219\n",
      "weighted avg       0.36      0.28      0.31       219\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Fit RBF model on best C (gamma='scale')\n",
    "lowest_val_error_index = np.argmin(cv_val_avg_score)\n",
    "C_chosen = C_values[lowest_val_error_index]\n",
    "\n",
    "print(f\"Best C = {C_chosen}, with lowest avg test error: {cv_val_avg_score[lowest_val_error_index]:.4f}\")\n",
    "\n",
    "\n",
    "final_model = SVC(kernel='rbf',C=C_chosen, gamma='scale')\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "final_test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred, average='weighted')  # Use 'macro' or 'weighted' for multi-class\n",
    "recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final Test Error: {final_test_error:.4f}\")\n",
    "print(f\"RBF SVM Performance Metrics with C={C_chosen}, gamma='scale':\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624f02a",
   "metadata": {},
   "source": [
    "RBF SVM with gamma = scale and gamma = auto performs comparably okay \n",
    "RBF SVM performs a lot more better with Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dae59e",
   "metadata": {},
   "source": [
    "DIY SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c2824a-ec66-4c91-8735-a2137dcfdb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement own version of SVM and tweak something?????\n",
    "#DIY SVM\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the trigonometric kernel function\n",
    "def rbf_kernel(X, Y, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Trigonometric kernel function as defined in the paper.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): Matrix of shape (n_samples_X, n_features).\n",
    "        Y (numpy.ndarray): Matrix of shape (n_samples_Y, n_features).\n",
    "        sigma (float): Kernel parameter.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Kernel matrix of shape (n_samples_X, n_samples_Y).\n",
    "    \"\"\"\n",
    "    pairwise_sq_dists = np.sum(X**2, axis=1)[:, np.newaxis] + np.sum(Y**2, axis=1) - 2 * np.dot(X, Y.T)\n",
    "    \n",
    "    # Compute the RBF kernel\n",
    "    return np.exp(-pairwise_sq_dists / (2 * sigma**2))\n",
    "# Custom kernel wrapper for scikit-learn\n",
    "class CustomKernelSVM(SVC):\n",
    "    def __init__(self, sigma=1.0, **kwargs):\n",
    "        super().__init__(kernel=\"precomputed\", **kwargs)\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Compute the kernel matrix for training data\n",
    "        self.X_fit_ = X\n",
    "        K = rbf_kernel(X, X, sigma=self.sigma)\n",
    "        return super().fit(K, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Compute the kernel matrix between training and test data\n",
    "        K = rbf_kernel(X, self.X_fit_, sigma=self.sigma)\n",
    "        return super().predict(K)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f50739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        38\n",
      "           2       0.18      1.00      0.31        47\n",
      "           3       0.00      0.00      0.00        41\n",
      "           4       0.00      0.00      0.00        46\n",
      "           5       0.00      0.00      0.00        47\n",
      "           6       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.18       257\n",
      "   macro avg       0.03      0.17      0.05       257\n",
      "weighted avg       0.03      0.18      0.06       257\n",
      "\n",
      "Final Test Error: 0.8171\n",
      "RBF SVM Performance Metrics with C=1.0, gamma='scale':\n",
      "Accuracy: 0.1829\n",
      "Precision: 0.0334\n",
      "Recall: 0.1829\n",
      "F1 Score: 0.0565\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 38  0  0  0  0]\n",
      " [ 0 47  0  0  0  0]\n",
      " [ 0 41  0  0  0  0]\n",
      " [ 0 46  0  0  0  0]\n",
      " [ 0 47  0  0  0  0]\n",
      " [ 0 38  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        38\n",
      "           2       0.18      1.00      0.31        47\n",
      "           3       0.00      0.00      0.00        41\n",
      "           4       0.00      0.00      0.00        46\n",
      "           5       0.00      0.00      0.00        47\n",
      "           6       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.18       257\n",
      "   macro avg       0.03      0.17      0.05       257\n",
      "weighted avg       0.03      0.18      0.06       257\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# diy_svm = MultiClassSVM()\n",
    "# diy_svm.fit(X_train, y_train)\n",
    "# y_test_pred = diy_svm.predict(y_test)\n",
    "\n",
    "svm = CustomKernelSVM(sigma=0.5, C=1.0, decision_function_shape=\"ovr\")\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_test_pred = svm.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "final_test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred, average='weighted')  # Use 'macro' or 'weighted' for multi-class\n",
    "recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final Test Error: {final_test_error:.4f}\")\n",
    "print(f\"RBF SVM Performance Metrics with C=1.0, gamma='scale':\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16ff2537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Error: 0.7237\n",
      "RBF SVM Performance Metrics with C=1.0, gamma='scale':\n",
      "Accuracy: 0.2763\n",
      "Precision: 0.2752\n",
      "Recall: 0.2763\n",
      "F1 Score: 0.2738\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 8  4 10  1  5 10]\n",
      " [ 2 18  7  8  3  9]\n",
      " [ 7  7 13  8  4  2]\n",
      " [ 2  9  5 17  7  6]\n",
      " [ 4 12  7  7 11  6]\n",
      " [ 8  3 10  6  7  4]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.21      0.23        38\n",
      "           2       0.34      0.38      0.36        47\n",
      "           3       0.25      0.32      0.28        41\n",
      "           4       0.36      0.37      0.37        46\n",
      "           5       0.30      0.23      0.26        47\n",
      "           6       0.11      0.11      0.11        38\n",
      "\n",
      "    accuracy                           0.28       257\n",
      "   macro avg       0.27      0.27      0.27       257\n",
      "weighted avg       0.28      0.28      0.27       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "pipeline = Pipeline([\n",
    "    ('pca', PCA(n_components=300)),  # Reduce to 300 components\n",
    "    ('svm', SVC(kernel='rbf', gamma='scale', C=10))  # SVM with RBF kernel\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "final_test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred, average='weighted')  # Use 'macro' or 'weighted' for multi-class\n",
    "recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final Test Error: {final_test_error:.4f}\")\n",
    "print(f\"RBF SVM Performance Metrics with C=1.0, gamma='scale':\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
