{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/giangto/Documents/umn/csci5525/5525Chess\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "current = os.getcwd()\n",
    "data_folder = os.path.join(current, \"normalized_images_128\")\n",
    "chess_types_folders = glob.glob(os.path.join(data_folder, \"*\"))\n",
    "# print(chess_types_folders)\n",
    "pieces_info = []\n",
    "labels = {\"King\": 1, \"Knight\":2, \"Bishop\":3, \"Rook\":4, \"Pawn\":5, \"Queen\":6}\n",
    "for chess_types in chess_types_folders:\n",
    "    pieces = glob.glob(f'{chess_types}/*')\n",
    "    # print(pieces)\n",
    "    type = chess_types.split(\"/\")[-1]\n",
    "    for piece in pieces:\n",
    "        p = {\"normalized_img\": np.load(piece).reshape(-1), \"label\": labels[type]}\n",
    "        pieces_info.append(p)\n",
    "chess_df = pd.DataFrame(pieces_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        normalized_img  label\n",
      "802  [0.22745098039215686, 0.21176470588235294, 0.2...      6\n",
      "763  [0.6235294117647059, 0.7372549019607844, 0.878...      6\n",
      "855  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      6\n",
      "808  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...      6\n",
      "824  [0.5568627450980392, 0.7647058823529411, 0.858...      6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/pqhy6s2j2lq2h7_jn7jz7gpr0000gn/T/ipykernel_785/949022291.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  chess_df = chess_df.applymap(lambda x: tuple(x) if isinstance(x, np.ndarray) else x)\n",
      "/var/folders/tp/pqhy6s2j2lq2h7_jn7jz7gpr0000gn/T/ipykernel_785/949022291.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  chess_test = chess_test.applymap(lambda x: tuple(x) if isinstance(x, np.ndarray) else x)\n"
     ]
    }
   ],
   "source": [
    "#sample df test set and df train set\n",
    "chess_test = pd.DataFrame()\n",
    "for i in range(1,7):\n",
    "    chess_i = chess_df[chess_df[\"label\"]==i].sample(frac=0.3)\n",
    "    chess_test = pd.concat([chess_i,chess_test])\n",
    "chess_test = chess_test[chess_df.columns]\n",
    "print(chess_test.head())\n",
    "chess_df = chess_df.applymap(lambda x: tuple(x) if isinstance(x, np.ndarray) else x)\n",
    "chess_test = chess_test.applymap(lambda x: tuple(x) if isinstance(x, np.ndarray) else x)\n",
    "\n",
    "# Merge\n",
    "chess_train = chess_df.merge(chess_test, how='left', indicator=True)\n",
    "chess_train = chess_train[chess_train['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "\n",
    "#mini dataset\n",
    "# chess_train = chess_train.sample(frac=0.5)\n",
    "# chess_test = chess_test.sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chess train label counts:\n",
      "label\n",
      "5    110\n",
      "2    109\n",
      "4    106\n",
      "3     96\n",
      "6     90\n",
      "1     88\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Chess test label counts:\n",
      "label\n",
      "5    47\n",
      "2    47\n",
      "4    46\n",
      "3    41\n",
      "6    38\n",
      "1    38\n",
      "Name: count, dtype: int64\n",
      "(599, 2)\n",
      "(257, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Chess train label counts:\")\n",
    "print(chess_train['label'].value_counts())\n",
    "print()\n",
    "print(\"Chess test label counts:\")\n",
    "print(chess_test['label'].value_counts())\n",
    "\n",
    "print(chess_train.shape)\n",
    "print(chess_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (599, 16384)\n",
      "X_test shape:  (257, 16384)\n"
     ]
    }
   ],
   "source": [
    "#Load dataset\n",
    "X_train = np.array(chess_train['normalized_img'])\n",
    "X_train = np.array([x for x in X_train])\n",
    "y_train = np.array(chess_train['label'])\n",
    "\n",
    "X_test = np.array(chess_test['normalized_img'])\n",
    "X_test = np.array([x for x in X_test])\n",
    "y_test = np.array(chess_test['label'])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement own version of SVM and tweak something?????\n",
    "#DIY SVM\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Define the trigonometric kernel function\n",
    "class SVM:\n",
    "    def __init__(self, kernel='linear', C=10000.0, max_iter=100000, degree=3, gamma=1, sigma=1):\n",
    "        self.kernel = {\n",
    "        'poly': lambda x, y: np.dot(x, y.T) ** degree,\n",
    "        'rbf': lambda x, y: np.exp(-gamma * np.sum((x[:, np.newaxis] - y) ** 2, axis=2)),\n",
    "        'linear': lambda x, y: np.dot(x, y.T),\n",
    "        'string': lambda x, y: np.sum(x[:, np.newaxis] == y, axis=2).astype(float),\n",
    "        'histogram_intersection': lambda x, y: np.sum(np.minimum(x[:, np.newaxis], y), axis=2),\n",
    "        'chi_square': lambda x, y: 1 - 0.5 * np.sum(((x[:, np.newaxis] - y) ** 2) / (x[:, np.newaxis] + y + 1e-10), axis=2),\n",
    "        'laplacian': lambda x, y: np.exp(-np.sum(np.abs(x[:, np.newaxis] - y), axis=2) / sigma),\n",
    "        'random_walk': lambda x, y: random_walk_kernel_placeholder(x, y),\n",
    "        }[kernel]\n",
    "        self.C = C\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    def random_walk_kernel_placeholder(x, y):\n",
    "        \"\"\"\n",
    "        Placeholder for a random walk kernel. Random walk kernels require graph representations.\n",
    "        This function should be replaced with an actual implementation.\n",
    "        \"\"\"\n",
    "        # Example: Return a dummy similarity matrix for demonstration purposes\n",
    "        return np.dot(x, y.T)  # Replace with graph-based computations\n",
    "\n",
    "    def restrict_to_square(self, t, v0, u):\n",
    "        t = (np.clip(v0 + t * u, 0, self.C) - v0)[1] / u[1]\n",
    "        return (np.clip(v0 + t * u, 0, self.C) - v0)[0] / u[0]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X.copy()\n",
    "        self.y = y * 2 - 1  # Convert labels to {-1, 1}\n",
    "        self.lambdas = np.zeros_like(self.y, dtype=float)\n",
    "        self.K = self.kernel(self.X, self.X)\n",
    "\n",
    "        # print(\"Kernel matrix shape:\", self.K.shape)\n",
    "        # print(\"Kernel matrix example:\", self.K[:5, :5])\n",
    "\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            for idxM in range(len(self.lambdas)):\n",
    "                idxL = np.random.randint(0, len(self.lambdas))\n",
    "                Q = self.K[[[idxM, idxM], [idxL, idxL]], [[idxM, idxL], [idxM, idxL]]]\n",
    "                v0 = self.lambdas[[idxM, idxL]]\n",
    "                k0 = 1 - np.sum(self.lambdas * self.K[[idxM, idxL]], axis=1)\n",
    "                u = np.array([-self.y[idxL], self.y[idxM]])\n",
    "                t_max = np.dot(k0, u) / (np.dot(np.dot(Q, u), u) + 1E-15)\n",
    "                self.lambdas[[idxM, idxL]] = v0 + u * self.restrict_to_square(t_max, v0, u)\n",
    "\n",
    "        idx = np.nonzero(self.lambdas > 1E-15)[0]  # Non-zero support vector indices\n",
    "        if len(idx) > 0:\n",
    "            self.b = np.sum((1.0 - np.sum(self.K[idx] * self.lambdas, axis=1)) * self.y[idx]) / len(idx)\n",
    "        else:\n",
    "            self.b = 0  # Default bias if no support vectors\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return np.sum(self.kernel(X, self.X) * self.y * self.lambdas, axis=1) + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        decision_values = self.decision_function(X)\n",
    "        return np.sign(decision_values)\n",
    "\n",
    "\n",
    "class MultiClassSVM:\n",
    "    def __init__(self, base_svm_class, n_classes, **svm_params):\n",
    "        self.n_classes = n_classes\n",
    "        self.models = [base_svm_class(**svm_params) for _ in range(n_classes)]  # One SVM per class\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train one binary SVM for each class (One-vs-Rest strategy).\n",
    "        \"\"\"\n",
    "        self.classes_ = np.unique(y)  # Unique class labels\n",
    "        for i, cls in enumerate(self.classes_):\n",
    "            binary_y = np.where(y == cls, 1, -1)  # Convert to binary labels: current class vs others\n",
    "            print(f\"Training SVM for class {cls} vs rest...\")\n",
    "            self.models[i].fit(X, binary_y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class for each input sample.\n",
    "        \"\"\"\n",
    "        decision_values = np.array([model.decision_function(X) for model in self.models])\n",
    "        normalized_scores = (decision_values - decision_values.min(axis=0)) / (decision_values.max(axis=0) - decision_values.min(axis=0))\n",
    "        predicted_classes = self.classes_[np.argmax(normalized_scores, axis=0)]\n",
    "\n",
    "        return predicted_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM for class 1 vs rest...\n",
      "Training SVM for class 2 vs rest...\n",
      "Training SVM for class 3 vs rest...\n",
      "Training SVM for class 4 vs rest...\n",
      "Training SVM for class 5 vs rest...\n",
      "Training SVM for class 6 vs rest...\n",
      "Classification Report:\n",
      "ytest:  [2 4 5 4 1 6 1 3 6 4 4 4 6 3 3 1 6 6 6 1 4 3 3 2 5 1 4 2 3 5 4 5 4 6 4 2 6\n",
      " 2 6 3 3 2 1 6 5 3 3 6 6 4 4 4 5 2 2 2 4 4 1 3 2 4 1 2 4 5 3 2 1 4 2 5 5 2\n",
      " 1 3 1 6 4 1 4 5 6 4 5 4 5 2 2 6 2 4 4 2 4 5 6 3 3 1 4 3 1 6 3 2 1 5 4 2 2\n",
      " 1 3 3 5 6 2 1 5 5 3 1 6 5 5 6 6 5]\n",
      "ypred:  [5 5 5 5 5 5 5 3 5 6 5 5 6 4 2 5 5 6 6 5 5 6 5 3 6 4 6 5 5 5 5 3 5 6 3 5 6\n",
      " 5 6 6 5 5 5 5 6 5 6 5 5 4 4 6 6 5 6 5 4 5 5 5 5 4 5 6 5 5 5 6 5 5 5 6 2 6\n",
      " 3 6 5 6 5 5 5 5 5 2 5 3 5 6 2 6 5 6 5 5 5 5 5 6 6 5 5 5 5 6 6 5 4 5 5 5 5\n",
      " 5 2 5 5 5 5 6 2 6 6 5 2 5 5 6 6 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        18\n",
      "           2       0.12      0.05      0.07        22\n",
      "           3       0.17      0.05      0.08        20\n",
      "           4       0.57      0.15      0.24        27\n",
      "           5       0.15      0.55      0.24        20\n",
      "           6       0.32      0.52      0.40        21\n",
      "\n",
      "    accuracy                           0.22       128\n",
      "   macro avg       0.22      0.22      0.17       128\n",
      "weighted avg       0.24      0.22      0.18       128\n",
      "\n",
      "Final Test Error: 0.7812\n",
      "RBF SVM Performance Metrics with C=1.0, gamma='scale':\n",
      "Accuracy: 0.2188\n",
      "Precision: 0.2447\n",
      "Recall: 0.2188\n",
      "F1 Score: 0.1757\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  1  2 14  1]\n",
      " [ 0  1  1  0 15  5]\n",
      " [ 0  2  1  1  8  8]\n",
      " [ 0  1  2  4 16  4]\n",
      " [ 0  3  1  0 11  5]\n",
      " [ 0  1  0  0  9 11]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        18\n",
      "           2       0.12      0.05      0.07        22\n",
      "           3       0.17      0.05      0.08        20\n",
      "           4       0.57      0.15      0.24        27\n",
      "           5       0.15      0.55      0.24        20\n",
      "           6       0.32      0.52      0.40        21\n",
      "\n",
      "    accuracy                           0.22       128\n",
      "   macro avg       0.22      0.22      0.17       128\n",
      "weighted avg       0.24      0.22      0.18       128\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#gamma = X_train.shape[1]\n",
    "svm = MultiClassSVM(SVM, n_classes=6, kernel='rbf', C=10, max_iter=10000, gamma=0.0001)\n",
    "\n",
    "# Train the multi-class SVM\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_test_pred = svm.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(\"ytest: \", y_test)\n",
    "print(\"ypred: \", y_test_pred) \n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "final_test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred, average='weighted')  # Use 'macro' or 'weighted' for multi-class\n",
    "recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final Test Error: {final_test_error:.4f}\")\n",
    "print(f\"RBF SVM Performance Metrics with C=1.0, gamma='scale':\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF with pca and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM for class 1 vs rest...\n",
      "Training SVM for class 2 vs rest...\n",
      "Training SVM for class 3 vs rest...\n",
      "Training SVM for class 4 vs rest...\n",
      "Training SVM for class 5 vs rest...\n",
      "Training SVM for class 6 vs rest...\n",
      "Classification Report:\n",
      "ytest:  [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "ypred:  [2 6 2 4 4 4 6 5 2 4 5 2 2 5 4 4 2 2 6 2 2 2 5 5 5 1 3 2 2 5 2 2 4 2 5 5 5\n",
      " 2 2 2 2 5 2 5 4 2 2 2 2 2 2 2 2 5 2 2 4 2 2 5 5 4 2 2 3 2 4 5 6 5 2 4 5 2\n",
      " 2 2 2 6 5 5 2 5 5 5 5 4 5 3 2 2 2 2 4 5 2 5 4 4 2 4 4 3 4 5 2 2 2 4 5 2 3\n",
      " 5 2 2 5 2 2 4 4 4 2 2 2 5 2 4 4 4 4 2 2 2 5 5 5 5 2 6 2 4 4 2 2 5 4 2 2 6\n",
      " 2 1 4 2 5 2 1 5 2 5 5 5 6 2 5 4 2 2 2 2 2 4 2 2 2 3 2 2 2 4 2 5 4 4 4 4 2\n",
      " 2 2 2 5 2 2 2 2 2 2 2 4 4 2 2 2 2 2 2 2 2 4 2 2 4 2 4 2 4 5 2 2 2 2 5 2 1\n",
      " 6 5 6 4 5 6 2 2 5 2 2 3 2 5 2 3 6 2 5 5 6 4 2 2 2 2 2 2 4 2 5 2 2 6 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.03      0.05        38\n",
      "           2       0.25      0.68      0.36        47\n",
      "           3       0.00      0.00      0.00        41\n",
      "           4       0.31      0.33      0.32        46\n",
      "           5       0.26      0.30      0.28        47\n",
      "           6       0.21      0.08      0.12        38\n",
      "\n",
      "    accuracy                           0.25       257\n",
      "   macro avg       0.21      0.24      0.19       257\n",
      "weighted avg       0.22      0.25      0.20       257\n",
      "\n",
      "Final Test Error: 0.7471\n",
      "Multi-Class SVM Performance Metrics with Laplacian Kernel:\n",
      "Accuracy: 0.2529\n",
      "Precision: 0.2174\n",
      "Recall: 0.2529\n",
      "F1 Score: 0.1984\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1 17  2  4  8  6]\n",
      " [ 0 32  1 11  3  0]\n",
      " [ 2 19  0  6 11  3]\n",
      " [ 0 20  3 15  8  0]\n",
      " [ 0 25  1  5 14  2]\n",
      " [ 1 16  1  7 10  3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.03      0.05        38\n",
      "           2       0.25      0.68      0.36        47\n",
      "           3       0.00      0.00      0.00        41\n",
      "           4       0.31      0.33      0.32        46\n",
      "           5       0.26      0.30      0.28        47\n",
      "           6       0.21      0.08      0.12        38\n",
      "\n",
      "    accuracy                           0.25       257\n",
      "   macro avg       0.21      0.24      0.19       257\n",
      "weighted avg       0.22      0.25      0.20       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Step 1: Standardize the features\n",
    "    ('pca', PCA(n_components=250)), \n",
    "    ('svm', MultiClassSVM(SVM, n_classes=6, kernel='rbf', C=1, max_iter=10000, gamma=0.001))  # Step 2: Train the Multi-Class SVM\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Classification metrics\n",
    "print(\"Classification Report:\")\n",
    "print(\"ytest: \", y_test)\n",
    "print(\"ypred: \", y_test_pred)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "final_test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred, average='weighted')  # Use 'macro' or 'weighted' for multi-class\n",
    "recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Final Test Error: {final_test_error:.4f}\")\n",
    "print(f\"Multi-Class SVM Performance Metrics with Laplacian Kernel:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM for class 1 vs rest...\n",
      "Training SVM for class 2 vs rest...\n",
      "Training SVM for class 3 vs rest...\n",
      "Training SVM for class 4 vs rest...\n",
      "Training SVM for class 5 vs rest...\n",
      "Training SVM for class 6 vs rest...\n",
      "Classification Report:\n",
      "ytest:  [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "ypred:  [4 1 4 2 2 3 4 4 4 5 4 1 5 4 3 1 2 4 4 4 4 4 6 3 5 4 4 6 5 4 6 4 6 4 1 4 4\n",
      " 4 6 6 4 4 4 4 4 6 4 4 6 1 5 1 1 4 6 4 2 1 1 5 6 6 4 4 4 4 6 1 1 4 6 6 4 4\n",
      " 5 4 4 4 4 4 4 4 4 2 4 4 4 5 4 5 6 4 4 4 5 4 4 4 5 4 4 4 6 3 4 3 4 4 1 4 5\n",
      " 4 2 6 4 1 1 1 4 6 4 2 4 4 1 1 2 5 1 4 4 4 5 4 4 4 4 6 1 1 4 6 4 1 4 1 4 6\n",
      " 4 5 6 6 4 2 4 4 1 5 4 4 5 4 4 5 2 4 2 6 6 4 2 5 4 1 5 6 4 4 6 5 6 5 4 6 4\n",
      " 4 6 4 4 6 4 4 4 6 4 3 4 4 6 4 6 2 2 3 4 5 4 2 5 4 4 6 4 4 5 4 4 2 2 4 6 2\n",
      " 5 4 4 5 3 4 3 4 6 4 6 4 3 6 6 2 6 6 4 4 4 4 6 4 5 2 2 1 6 6 6 1 4 4 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.05      0.06        38\n",
      "           2       0.24      0.11      0.15        47\n",
      "           3       0.00      0.00      0.00        41\n",
      "           4       0.19      0.52      0.28        46\n",
      "           5       0.11      0.06      0.08        47\n",
      "           6       0.09      0.11      0.10        38\n",
      "\n",
      "    accuracy                           0.15       257\n",
      "   macro avg       0.12      0.14      0.11       257\n",
      "weighted avg       0.12      0.15      0.11       257\n",
      "\n",
      "Final Test Error: 0.8521\n",
      "RBF SVM Performance Metrics with C=1.0, gamma='scale':\n",
      "Accuracy: 0.1479\n",
      "Precision: 0.1215\n",
      "Recall: 0.1479\n",
      "F1 Score: 0.1148\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2  4  3 15  3 11]\n",
      " [ 1  5  2 23  6 10]\n",
      " [ 5  4  0 19  6  7]\n",
      " [ 7  3  2 24  6  4]\n",
      " [ 7  2  0 25  3 10]\n",
      " [ 4  3  3 20  4  4]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.05      0.06        38\n",
      "           2       0.24      0.11      0.15        47\n",
      "           3       0.00      0.00      0.00        41\n",
      "           4       0.19      0.52      0.28        46\n",
      "           5       0.11      0.06      0.08        47\n",
      "           6       0.09      0.11      0.10        38\n",
      "\n",
      "    accuracy                           0.15       257\n",
      "   macro avg       0.12      0.14      0.11       257\n",
      "weighted avg       0.12      0.15      0.11       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Step 1: Standardize the features\n",
    "    ('pca', PCA(n_components=250)), \n",
    "    ('svm', MultiClassSVM(SVM, n_classes=6, kernel='chi_square', C=10, max_iter=10000, gamma=0.001))  # Step 2: Train the Multi-Class SVM\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Predict and evaluate\n",
    "print(\"Classification Report:\")\n",
    "print(\"ytest: \", y_test)\n",
    "print(\"ypred: \", y_test_pred) \n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "final_test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred, average='weighted')  # Use 'macro' or 'weighted' for multi-class\n",
    "recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final Test Error: {final_test_error:.4f}\")\n",
    "print(f\"RBF SVM Performance Metrics with C=1.0, gamma='scale':\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
